{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to collect google places API results based on coordinates and write out a resulting json file 'taxi_blocks_google_places_all.txt'. It will also create another csv file as an output which is a summary of the count of the type of places that are available associated to each block_id.  This notebook requires libraries from the below cell and the summarized dataset 'taxi_blocks.csv' be available in the working directory. The dataset contains coordinates of the most frequently utilized coordinates in the NYC taxi dataset, 'taxi_blocks.csv' which is required to run this script. This script is in a notebook format since the API occasionally times out and is easiest to restart to get the complete data.\n",
    "\n",
    "The API returns the results in JSON and is ordered by prominence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from googleplaces import GooglePlaces, types, lang ##pip install python-google-places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_distance(origin, destination):\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371 # km\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = int(radius * c * 1000)/1000.0\n",
    "\n",
    "    return d #in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Make sure the file is available\n",
    "data = pd.read_csv('taxi_blocks.csv')\n",
    "##These types are used for the API call\n",
    "types_to_query = [['point_of_interest'], ['restaurant'], ['bar'], ['store'], ['lodging'], ['subway_station']]\n",
    "\n",
    "##Obtain API key from Google Places\n",
    "API_KEY = ''\n",
    "google_places = GooglePlaces(API_KEY)\n",
    "\n",
    "##Initiate dictionary\n",
    "google_places_result = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use below cell if it times out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##If the API times out check to see what the last block_id number was and then restart by executing the below cell.\n",
    "data = data[data['block_id'] > 485]\n",
    "data.index=range(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Loop through each of the block_id coordinates\n",
    "for index, row in data.iterrows():\n",
    "    block_id = int(data.iloc[index]['block_id']) \n",
    "    google_places_result[block_id] = {} ##initialize dictionary with block_id within parent dict\n",
    "    #google_places_result[block_id]['lat'] = data.iloc[index]['latitude']\n",
    "    #google_places_result[block_id]['lng'] = data.iloc[index]['longitude']\n",
    "    lon_lat = {'lat': data.iloc[index]['latitude'], 'lng': data.iloc[index]['longitude']} ##input for API call\n",
    "    for a in types_to_query: ##start loop for the various types declared above\n",
    "        query_result = google_places.nearby_search(lat_lng = lon_lat, radius = 500, types = a) ##API call \n",
    "        for place in query_result.places: ##start extraction of JSON results\n",
    "            if place.place_id not in google_places_result[block_id]: ##check if unique place id is already included \n",
    "                ##insert data name, types and distance for unique place id\n",
    "                google_places_result[block_id][place.place_id] = {'name': place.name, 'type': place.types, \n",
    "                    'dist': coord_distance((float(place.geo_location['lat']), \n",
    "                                            float(place.geo_location['lng'])), \n",
    "                                           (data.iloc[index]['latitude'], data.iloc[index]['longitude']))}\n",
    "                place.get_details() ##additional API call to retrieve more info\n",
    "                if 'opening_hours' in place.details.keys(): ##insert opening_hours if available\n",
    "                    google_places_result[block_id][place.place_id]['opening_hours'] = place.details['opening_hours']['weekday_text']\n",
    "                if 'address_components' in place.details.keys(): ##insert neighborhood if available, else None\n",
    "                    google_places_result[block_id][place.place_id]['neighborhood'] = next(\n",
    "                        (item['short_name'] for item in place.details['address_components'] \n",
    "                                 if item[\"types\"] == ['neighborhood', 'political']), None)\n",
    "    ##One last call without types\n",
    "    query_result = google_places.nearby_search(lat_lng = lon_lat, radius = 500)\n",
    "    for place in query_result.places:\n",
    "        if place.place_id not in google_places_result[block_id]:\n",
    "            google_places_result[block_id][place.place_id] = {'name': place.name, 'type': place.types, \n",
    "                'dist': coord_distance((float(place.geo_location['lat']), \n",
    "                                        float(place.geo_location['lng'])), \n",
    "                                        (data.iloc[index]['latitude'], data.iloc[index]['longitude']))}\n",
    "            place.get_details()\n",
    "            if 'opening_hours' in place.details.keys():\n",
    "                google_places_result[block_id][place.place_id]['opening_hours'] = place.details['opening_hours']['weekday_text']\n",
    "            if 'address_components' in place.details.keys():\n",
    "                google_places_result[block_id][place.place_id]['neighborhood'] = next(\n",
    "                    (item['short_name'] \n",
    "                    for item in place.details['address_components'] \n",
    "                        if item[\"types\"] == ['neighborhood', 'political']), None)\n",
    "\n",
    "##Output JSON file\n",
    "google_places_result_json = {str(k):v for k,v in google_places_result.items()}\n",
    "google_places_result_json = json.dumps(google_places_result_json, ensure_ascii=False)\n",
    "with open('taxi_blocks_google_places_all.txt', 'w') as outfile:\n",
    "    json.dump(google_places_result, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you already have the file taxi_blocks_google_places_all.txt start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Load data if necessary\n",
    "with open('taxi_blocks_google_places_all.txt') as json_data:\n",
    "    google_places_result = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##This will output a file that includes count of the various types per block_id\n",
    "block_id_type = {} ##type dictionary\n",
    "type_list = [] ##keeps tab of all the types\n",
    "ignore_type = ['locality', 'sublocality_level_1', 'point_of_interest', 'sublocality', 'political', 'establishment'] ##ignore these\n",
    "for key_init, values_dict in google_places_result.iteritems():\n",
    "    block_id_type[key_init] = {} ##initialize dict for block_id\n",
    "    for key, values in values_dict.iteritems():\n",
    "        ##find first index which is not in the ignore type\n",
    "        index_not_ignore_type = next((values['type'].index(item) for item in values['type'] if item not in ignore_type), 0)\n",
    "        if values['type'][index_not_ignore_type] not in block_id_type[key_init]: ##initialize if first one\n",
    "            block_id_type[key_init][values['type'][index_not_ignore_type]] = 1 \n",
    "            if values['type'][index_not_ignore_type] not in type_list: ##append to type list if first\n",
    "                type_list.append(values['type'][index_not_ignore_type])\n",
    "        else: ##add one when type appears again\n",
    "            block_id_type[key_init][values['type'][index_not_ignore_type]] += 1\n",
    "block_id_type_pd = pd.DataFrame(index = block_id_type.keys(), columns=type_list) ##initialize pandas dataframe\n",
    "\n",
    "for key, value in block_id_type.iteritems(): ##update the value column with block_id key\n",
    "    block_id_type_pd.loc[key] = pd.Series(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "block_id_type_pd.to_csv('place_type_count_by_blockid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
